<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <style>
      body {
        font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
        font-size: 9pt;
        line-height: 1.3;
        color: #333;
        margin: 30px 40px;
      }
      h1 {
        font-size: 16pt;
        margin-bottom: 1px;
        color: #1a1a1a;
        text-align: center;
      }
      h1 + p {
        text-align: center;
        font-size: 8pt;
        color: #555;
        margin: 1px 0 8px 0;
      }
      h2 {
        font-size: 10pt;
        color: #2c3e50;
        border-bottom: 1.2px solid #2c3e50;
        padding-bottom: 2px;
        margin-top: 10px;
        margin-bottom: 4px;
        text-transform: uppercase;
        letter-spacing: 0.4px;
      }
      h3 {
        font-size: 9.5pt;
        margin-top: 6px;
        margin-bottom: 2px;
        color: #1a1a1a;
      }
      p {
        margin: 2px 0;
      }
      ul {
        margin: 2px 0;
        padding-left: 16px;
      }
      li {
        margin-bottom: 2px;
        font-size: 8.5pt;
      }
      strong {
        color: #1a1a1a;
      }
      table {
        width: 100%;
        border-collapse: collapse;
        font-size: 8pt;
        margin-top: 4px;
      }
      th,
      td {
        text-align: left;
        padding: 2px 4px;
        border-bottom: 1px solid #eee;
      }
      th {
        background: #f5f5f5;
        font-weight: bold;
      }
    </style>
  </head>
  <body>
    <h1>ZHENYU YANG</h1>
    <p>
      Toronto, ON · PR · +1 (425) 230-7227 · yangzhenyu528@gmail.com ·
      linkedin.com/in/zhenyu-yang-740b14275 · github.com/JuliusYang3311/verso-agent
    </p>

    <h2>Professional Summary</h2>
    <p>
      AI Infrastructure Engineer and Full-Stack Developer with
      <strong>2+ years AWS expertise</strong> building production-grade Generative AI systems.
      Specialized in architecting autonomous agent platforms, enterprise ML pipelines, and scalable
      RAG systems, translating cutting-edge AI research into production-ready infrastructure.
    </p>

    <h2>AWS Certifications</h2>
    <p>
      <a
        href="https://cp.certmetrics.com/amazon/en/public/verify/credential/6be3e5c5c4404c9fb6fea1deb0f9b4f0"
        style="color: #2c3e50; text-decoration: underline"
        >AWS Certified Machine Learning – Specialty</a
      >
    </p>
    <p>
      <a
        href="https://cp.certmetrics.com/amazon/en/public/verify/credential/469ca111d3df4a82b66d8878188720bf"
        style="color: #2c3e50; text-decoration: underline"
        >AWS Certified Cloud Practitioner</a
      >
    </p>

    <h2>Projects</h2>

    <h3>Verso AI — Autonomous Agent Platform | Creator & Lead Architect | Dec 2025 – Present</h3>
    <ul>
      <li>
        <strong>Self-Evolving Engine (GEP):</strong> Designed Genetic Expression Programming
        pipeline for autonomous code optimization. Extracts runtime signals, generates mutations via
        AST transformation, validates in sandboxed <strong>Docker</strong> environments,
        auto-deploys or rolls back. <strong>92% self-healing rate</strong>,
        <strong>500+ daily invocations</strong>, zero manual intervention.
      </li>
      <li>
        <strong>Three-Layer Memory (L0/L1/L2):</strong> Architected progressive retrieval — L0
        summaries (~100 tokens) for file pre-filtering, L1 overviews (~500 tokens) for structure, L2
        full text on-demand. Hierarchical search with hybrid scoring (vector 0.7 + BM25 0.3), score
        propagation (α=0.7), adaptive thresholds. <strong>+42% retrieval accuracy</strong> vs. fixed
        top-k RAG, <strong>3.2× information density</strong>.
      </li>
      <li>
        <strong>Async Execution:</strong> Decoupled I/O from agent Turn execution. Turns run as
        background tasks with steer() injection for new messages. Priority queuing, graceful
        cancellation, state persistence. <strong>&lt;900ms P95 tool call latency</strong>,
        <strong>+5× concurrent processing capacity</strong>.
      </li>
      <li>
        <strong>Dynamic Context Builder:</strong> Token-budget-aware assembler balancing recent
        messages vs. retrieved knowledge. Sliding window with exponential decay, automatic
        summarization. Input tokens controlled within <strong>200k limit</strong>. Conversation
        rounds <strong>+65%</strong> without session restart.
      </li>
      <li>
        <strong>Smart Router:</strong> Real-time complexity scoring routes tasks to optimal models
        (Flash/Sonnet/Opus). Provider failover with exponential backoff, circuit breaking,
        cost-aware load balancing. <strong>40% token cost reduction</strong>,
        <strong>&lt;300ms P95 latency</strong>.
      </li>
    </ul>

    <h3>OpenClaw Contributor (PR #9123) | Open Source</h3>
    <ul>
      <li>
        Designed smart routing system with complexity-based model selection, provider abstraction
        supporting 10+ LLM providers, unified error handling. Contributed plugin architecture.
        Adopted by 15+ contributors, serving 1M+ monthly requests.
      </li>
    </ul>

    <h3>Independent AI Engineer / Consultant | Freelance | Jan 2025 – Present</h3>
    <ul>
      <li>
        <strong>RAG Search Service:</strong> Built production hybrid retrieval (<strong
          >OpenSearch</strong
        >
        vector + BM25) with <strong>Redis</strong> embedding cache, async batch indexing,
        cross-encoder re-ranking. Optimized index sharding for 100K+ docs.
        <strong>&lt;300ms P95 latency</strong>, <strong>89% precision</strong>. Reduced
        infrastructure costs 35%.
      </li>
      <li>
        <strong>Serverless Pipelines:</strong> Designed event-driven architectures (<strong
          >AWS Lambda + Step Functions + EventBridge</strong
        >) with DLQs, exponential backoff, circuit breakers, idempotency keys. Auto-scales
        <strong>0 to 10K+ concurrent invocations</strong>. 99.9% uptime, zero-maintenance.
      </li>
      <li>
        <strong>LLM Integration:</strong> Deployed <strong>AWS Bedrock</strong> models with custom
        prompt engineering, A/B testing framework, structured output validation. Improved client
        engagement <strong>+25%</strong>, reduced hallucination rate 40%.
      </li>
    </ul>

    <h2>Experience</h2>
    <h3>
      Ji Heng Xiang | Founder & Full-Stack Engineer | Jan 2025 – Present |
      <a href="https://jihengxiang.com/" style="color: #2c3e50; text-decoration: underline"
        >jihengxiang.com</a
      >
    </h3>
    <ul>
      <li>
        Founded and built full-stack web application with <strong>AWS</strong> cloud infrastructure,
        <strong>CI/CD</strong> pipeline, user authentication, and session management. Manage
        platform operations and business development.
      </li>
      <li>
        Developed LLM-powered chatbot for mysticism consultation with custom
        <strong>RAG</strong> knowledge base for divination and spiritual guidance. Provide
        end-to-end client consultations leveraging AI-enhanced conversational interface.
      </li>
    </ul>

    <h3>
      INRIA (French National Institute for Research in Digital Science) | Research Intern | Jul –
      Dec 2023
    </h3>
    <ul>
      <li>
        Built high-fidelity C++ agent-based simulation (<strong>R² = 0.93</strong> vs. wet-lab
        data). Implemented spatial hashing (O(1) lookup), cache-aligned memory, SIMD-friendly
        structures. Profiled with perf, optimized hot paths — <strong>5× runtime reduction</strong>.
        Scaled to 1M+ agents with real-time visualization.
      </li>
    </ul>

    <h2>Technical Skills</h2>
    <table>
      <tr>
        <th>Domain</th>
        <th>Technologies</th>
      </tr>
      <tr>
        <td><strong>Cloud (AWS)</strong></td>
        <td>Lambda, Step Functions, Bedrock, SageMaker, Glue, Athena, EventBridge, IAM, SAM</td>
      </tr>
      <tr>
        <td><strong>LLM & Agents</strong></td>
        <td>
          Agentic Workflows, Function Calling, Tool-Use, MCP, ReAct/CoT, RAG, Self-Evolving Systems
          (GEP), Prompt Engineering
        </td>
      </tr>
      <tr>
        <td><strong>Infrastructure</strong></td>
        <td>
          Vector DBs (sqlite-vec, OpenSearch, Pinecone), Hybrid Retrieval, Dynamic Context, Model
          Routing, Async Execution
        </td>
      </tr>
      <tr>
        <td><strong>Languages</strong></td>
        <td>TypeScript, Python, C++, SQL</td>
      </tr>
      <tr>
        <td><strong>Tools</strong></td>
        <td>FastAPI, Docker, Git, CI/CD (GitHub Actions), PyTorch, Scikit-Learn</td>
      </tr>
    </table>

    <h2>Education</h2>
    <p>
      <strong>Ghent University</strong> | M.Sc. Bioinformatics,
      <strong>Distinction degree</strong> | 2022 – 2024 | Ghent, Belgium<br />
      <strong>Ocean University of China</strong> | B.Sc. Mathematics | 2018 – 2022 | Qingdao, China
    </p>
  </body>
</html>
